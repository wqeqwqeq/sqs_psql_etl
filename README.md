## Install dependency
Assume you have already installed docker and make on your system...

```make pip_install```

## Start docker container

```make start ```

## Create login_queue

When I run this on my PC, after run docker compose, the login_queue is not automatically created, looks like the 01_call_python_scripts.sh
does not run as expected, so if you can run 

```
awslocal sqs receive-message --queue-url http://localhost:4566/000000000000/login-queue
```

, which means your queue is successfully created by docker compose

However if not, run

```
$ docker ps                                                                                                                                                                                                 
CONTAINER ID   IMAGE                          COMMAND                  CREATED         STATUS         PORTS                                                                                            NAMES
a613d56a99e5   postgres:10                    "docker-entrypoint.sâ€¦"   9 minutes ago   Up 9 minutes   0.0.0.0:5432->5432/tcp                                                                           sqs_psql_etl_postgres_1                                                                                                                                                                                          
809eb9c75975   localstack/localstack:0.14.3   "docker-entrypoint.sh"   9 minutes ago   Up 9 minutes   127.0.0.1:443->443/tcp, 127.0.0.1:4510-4559->4510-4559/tcp, 127.0.0.1:4566->4566/tcp, 5678/tcp   sqs_psql_etl_localstack_1  
```

Then find the hash code for container created by localstack image, mine is `809eb9c75975`

Then run following

```
$ docker exec -it 809e bash                                                                                                                                                                                 
root@809eb9c75975:/opt/code/localstack# python /tmp/scripts/create_and_write_to_queue.py                                                                                                                    
queue_url: [http://localhost:4566/000000000000/login-queue]                                                                                                                                                 
root@809eb9c75975:/opt/code/localstack# exit                                                                                                                                                                
exit    
```

## create_key

This steps is to create public and private key generated by RSA, will be use to encrypt and decrypt ip and device id

```
make create_key
```

## Run code 

Basically run `make etl` will kick off the etl, `make health_check` will do a count for number of rows in psql
 
```
282710@root: ~/docker_project/sqs_psql_etl  (master)                                                                                                                                                        
$ make etl                                                                                                                                                                                                  
python -m etl                                                                                                                                                                                               
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Processed 10 messages                                                                                                                                                                                       
Finished parsing                                                                                                                                                                                            
current batch size is 100                                                                                                                                                                                   
Error message {'foo': 'oops_wrong_msg_type', 'bar': '123'}                                                                                                                                                  
                                                                                                                                                                                                            
282710@root: ~/docker_project/sqs_psql_etl  (master)                                                                                                                                                        
$ make health_check                                                                                                                                                                                         
python -m health                                                                                                                                                                                            
Number of rows in user_logins now is 99                                                                                                                                                                     
                                                                                                                                                                                                            
```

For `app_version`, since the target schema is *int*, however the value from queue's dtype is *varchar*, so I replace the **.** and apply *int()* to convert `app_version` to integer

I don't think *int* is the correct dtype in the target schema 

## Decrypt example

Make sure run this python code in the root directory of the project

```python
from encoding import load_key, encrypt, decrypt, public_file, private_file

public, private = load_key(public_file, private_file)
msg = "hello world"
encrypt_msg = encrypt(msg, public)
decrypt_msg = decrypt(encrypt_msg, private)


print("Original msg is:", msg)
# original msg is: hello world                                                                                                                                                                                
print("Encoded msg is:", encrypt_msg)
# encoded msg is: O5PZNgVPFea1D9qZjogHK5AvsOJdutHitnLPA9OiANk=                                                                                                                                                
print("Decoded msg is:", decrypt_msg)
# decoded msg is: hello world   

```


## Answers to Questions 

### How would you deploy this application in production?
We can deploy this code to AWS Lambda, and use `create-event-source-mapping` (AWS Kinesis can do, so I assume SQS can do the same thing) 
to connect with the SQS queue

Since the code is processing batch (you can define in chunk_size in etl.py) and will not process duplicated message (once the message is received, it will be deleted from the queue),
we can have many lambda functions listen to the same Queue, and insert to psql at the same time

### What other components would you want to add to make this production ready?

I am not pretty sure if multiple insert query to the same psql instance is doable, if not, we may need to insert different batch from the lambda in order

Also we can create lambda functions for health check as well


### How can this application scale with a growing data set.

We can increase the number of SQS queue, the number of lambda functions and the number of psql container. I assume we can have some may to merge different psql container into one


### How can PII be recovered later on?

see the decrypt example, we can run that function to each encrypt value 
